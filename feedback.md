# Assignment Feedback: Week 4: Dimensionality Reduction

**Student:** Rushi021
**Total Score:** 24/40 (60.0%)

**Grade Category:** D (Poor)

---

## Problem Breakdown

### Exercise 1 (11/16 = 68.8%)

**Part pipeline-part1** (pipeline-part1.code): 0/0 points

_Feedback:_ Your submission only includes the template data loading/splitting. Missing the required PCA reduction and 2D scatter plot colored by digit. Implement PCA(n_components=2), transform data, and visualize with a scatter plot using y as colors.

**Part pipeline-part2** (pipeline-part2.code): 2/4 points

_Feedback:_ Good job: PCA to 2D and clear scatter plot colored by class are correct and well-presented. However, the scree plot (first 40 components, percent variance explained) is missing—no computation or visualization provided. Add that for full credit.

**Part pipeline-part3** (pipeline-part3.code): 4/4 points

_Feedback:_ Excellent job. You fit PCA with 40 components on the training set, computed explained variance ratios as percent, and plotted a clear scree plot with correct labels and range. This fully meets the requirements for the scree plot.

**Part pipeline-part4** (pipeline-part4.code): 4/4 points

_Feedback:_ Correct: you fit PCA on the training set, computed cumulative explained variance, and found the smallest n achieving ≥95%. This fulfills the task and should work as intended. Nice job.

**Part pipeline-part5** (pipeline-part5.code): 1/4 points

_Feedback:_ You only re-plotted the original digit. Step 5 asks to visualize the digit after reducing to the number of components from Step 4. Use PCA(n_components=n_components_95), transform the digit, inverse_transform to reconstruct, then plot that reconstruction (or plot its reduced coor

---

### Exercise 2 (5/10 = 50.0%)

**Part ex1-part1** (ex1-part1.code): 1/4 points

_Feedback:_ You implemented PCA compression/reconstruction for one digit, not a t-SNE visualization. The task requires computing a 2D t-SNE embedding of MNIST and plotting a scatter colored by labels. Use TSNE(n_components=2).fit_transform(X_mnist_train) and scatter with c=y_mnist_train.

**Part ex1-part2** (ex1-part2.code): 1/3 points

_Feedback:_ You ran KNN on raw and PCA(80%) (good) and computed a t-SNE embedding/plot, but you didn’t train/evaluate KNN on the t-SNE features or report its performance. Add a train/test split on t-SNE (or transform train/test separately), fit KNN, and print accuracy.

**Part ex1-part3** (ex1-part3.code): 3/3 points

_Feedback:_ Great job. You trained KNN on the 2D t-SNE embedding with a proper train/test split and reported accuracy, plus a brief interpretation. This directly answers the prompt about KNN performance on t-SNE features.

---

### Exercise 4 (8/14 = 57.1%)

**Part ex2-part1** (ex2-part1.code): 0/0 points

_Feedback:_ Your code doesn’t follow the exercise: it uses undefined MNIST variables (X_mnist_train, y_mnist_train) instead of the provided synthetic X,y; no PCA vs UMAP comparison across dimensions; no KNN accuracy computation; only a UMAP plot. Please apply PCA/UMAP to X,y and report KNN r

**Part ex2-part2** (ex2-part2.code): 2/7 points

_Feedback:_ You correctly evaluated KNN on your prior UMAP 2D embedding with a proper split. However, Exercise 4 asked to use the provided synthetic data, compare PCA vs UMAP, vary dimensionality, try different UMAP parameters, and visualize embeddings. Add those analyses and plots.

**Part ex2-part3** (ex2-part3.answer): 6/7 points

_Feedback:_ Good work: you varied PCA/UMAP dims and UMAP params, evaluated with KNN, and provided a PCA visualization. Explanation aligns with your results, though “0.65%” likely means 65%. To improve: add UMAP plots and clarify why PCA 3D wins (class separation along z).

---

## Additional Information

This feedback was automatically generated by the autograder using LLM-based evaluation.

**Generated:** 2025-10-27 18:51:28 UTC

If you have questions about your grade, please reach out to the instructor.

---

*Powered by [Grade-Lite](https://github.com/your-repo/grade-lite) Autograder*